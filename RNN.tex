%% Copyright 2009 Elsevier Ltd
%%
%% This file is part of the 'Elsarticle Bundle'.
%% ---------------------------------------------
%%
%% It may be distributed under the conditions of the LaTeX Project Public
%% License, either version 1.2 of this license or (at your option) any
%% later version.  The latest version of this license is in
%%    http://www.latex-project.org/lppl.txt
%% and version 1.2 or later is part of all distributions of LaTeX
%% version 1999/12/01 or later.

\documentclass[preprint,12pt]{elsarticle}
\usepackage{graphicx}
\usepackage{lineno}

%\journal{Journal Name}

\begin{document}

\begin{frontmatter}

\title{Using Recurrent Neural Nets to Identify Isolated Leptons in High Energy Particle Collision Data}

\author{Ben Hooberman, Anil Radhakrishnan, Matt Zhang}

\address{UIUC}

\begin{abstract}
We demonstrate the use of recurrent neural nets (RNNs) for classifying leptons in particle collisions as either coming from prompt interactions or heavy flavor decays. This method is shown to improve upon current methods for lepton isolation, such as ptcone and PLT.
\end{abstract}

\end{frontmatter}

\section{Introduction}\label{sec:intro}

% why lepton isolation is important, what analyses it's used in etc

In high energy physics experiments at the Large Hadron Collider (LHC), we shoot protons at each other at nearly the speed of light, and each resulting collision causes a spray of particles to be produced. By analyzing a large number of these collisions with specialized detectors, we can work out the physics of what happened in these events.

These collisions often produce particles called leptons, which include electrons, muons, and their antimatter partners. For many physics analyses, we're interested in knowing whether each lepton was produced during the initial collision (prompt lepton), or whether it came into being slightly afterwards, when a heavier particle such as a b-quark decayed into lighter particles (heavy-flavor lepton).

When leptons come from quark decay, they are often surrounded by a shower of other particles when they reach the detector. Thus, we often use lepton-isolation algorithms to determine whether leptons are prompt or heavy-flavor (HF).

% existing techniques - PLT, ptcone etc.

Common algorithms for determining lepton isolation include ptcone and its variants such as ptvarcone. This algorithm simply draws a cone around each lepton - with the collision point as the vertex of the cone - and adds up the energy of all the other stuff inside that cone. If the ratio of lepton energy vs. non-lepton energy inside that cone is below a certain threshold, the lepton is marked as non-isolated (and thus as having come from a heavy decay). The size of the cone and cutoff threshold may vary with lepton energy and other factors, but for the most part the ptcone class of algorithms describe a simple sum and ratio.

There have also been investigations into other sorts of algorithms, such as the Prompt Lepton Tagger tool (PLT). The PLT algorithm calculates a set of features for each lepton, and uses these features to train a boosted decision tree (BDT). The results have been shown to outperform ptcone.

% why RNN would be useful

In this paper we demonstrate a further improvement upon lepton isolation algorithms, with the use of a recurrent neural net (RNN) evaluated on full track and calorimeter information for all particles surrounding a lepton. Rather than using a simple sum-and-ratio technique, or performing cut-based analysis on a small number of calculated features, we use a machine-learning algorithm to analyze all available information in an event in order to perform the best classification possible.

In Section~\ref{sec:selection}, we explain how we chose training and test events to use with our RNN, including what filtering and cleaning steps events had to pass. Section~\ref{sec:dataprep} includes technical details on data preparation, explaining how to prepare detector data and get it into a form usable for our studies. Section~\ref{sec:architecture} shows our investigations into the best architecture for our problem, and demonstrates how we decided on our final RNN architecture. Finally, results are shown in Section~\ref{sec:results}, comparing RNN results with ptcone and PLT.

The codebase used in this project can be found on GitHub at github.com/ BucketOfFish/LeptonIsolation. All training is performed with PyTorch.

\section{Event Selection}\label{sec:selection}

The leptons used in this project, both prompt and heavy-flavor, were extracted from a Monte-Carlo ttbar sample.
%To be specific, we used the sample $mc16_13TeV.410470.PhPy8EG_A14_ttbar_hdamp258p75_nonallhad.deriv.DAOD_MUON5.e6337_e5984_s3126_r10201_r10210_p3584$.
After lepton and track selections were applied, we ended up extracting 8241 heavy flavor and 8241 isolated leptons, with their associated tracks.

Electrons were selected using the “DFCommonElectronsLHMedium” decorator, and muons were selected using MuonSelectionTool set at medium. Furthermore, we only kept leptons which had at least one associated track in the surrounding region.

[TRACK SELECTIONS]

\section{Data Preparation}\label{sec:dataprep}

[DATA FORMAT, ROOT TO H5]

For each lepton, we stored the following information: pdgID, pT, eta, phi, d0, z0, ptcone(20/30/40), ptvarcone(20/30/40), and truthType. pdgID and truthType were truth information, specifying the lepton flavor (electron vs. muon) and lepton isolation (heavy flavor vs. prompt) respectively. For tracks, we stored dR, dEta, dPhi, dd0, dz0, charge, eta, pT, theta, d0, z0, and chiSquared. dR, dEta, etc. for each track were calculated with respect to the track's associated lepton.

\subsection{Feature Comparisons}

[FEATURE COMPARISONS]

\subsection{Ptcone Validation}

[HOW PTCONE IS CALCULATED]

[COMPARISON PLOTS]

\section{RNN Architecture}\label{sec:architecture}

[ORDERING INVESTIGATION (PT, DR, ETA, ETC.)]

[HYPERPARAMETER OPTIMIZATION]

[RNN VS GRU VS LSTM]

[RNN VS POINT CLOUD]

\section{Results Comparison}\label{sec:results}

[PTCONE OPTIMIZATION]

[PLT OPTIMIZATION]

[ROC CURVE COMPARISON]

\section{Conclusion}\label{sec:conclusion}

\bibliographystyle{bibstyle}
\bibliography{bibliography.bib}

\end{document}